{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-03T09:02:37.999838Z",
     "start_time": "2024-08-03T09:02:33.351284Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from helpers.datasets import CrackDataset\n",
    "from helpers.early_stopping import EarlyStopping\n",
    "from helpers.selective_search import generate_proposals, get_label_for_proposal, get_best_bbox_for_proposal"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T09:02:38.008973Z",
     "start_time": "2024-08-03T09:02:38.001844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BackboneNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "backbone_model = BackboneNetwork()"
   ],
   "id": "8faa8afd93742238",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T09:02:54.445503Z",
     "start_time": "2024-08-03T09:02:38.009983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RCNN(nn.Module):\n",
    "    def __init__(self, feature_extractor: nn.Module, in_shape: tuple[int, int], num_classes: int = 10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 3, in_shape[0], in_shape[1])\n",
    "            feature_output = self.feature_extractor(dummy_input)\n",
    "            feature_size = feature_output.view(-1).size(0)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(feature_size, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(feature_size, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        class_logits = self.classifier(features)\n",
    "        bbox_preds = self.regressor(features)\n",
    "        \n",
    "        return class_logits, bbox_preds\n",
    "\n",
    "\n",
    "rcnn_model = RCNN(backbone_model, (224, 224))"
   ],
   "id": "5166731b1376a831",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T09:03:02.107535Z",
     "start_time": "2024-08-03T09:02:54.447508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def list_image_paths(directory: str) -> list[str]:\n",
    "    return [os.path.join(directory, file) for file in os.listdir(directory)]\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "criterion_class = nn.CrossEntropyLoss()\n",
    "criterion_bbox = nn.SmoothL1Loss()\n",
    "optimizer = optim.Adam(rcnn_model.parameters(), lr=0.001)\n",
    "train_images_dir = os.path.join(\"data\", \"train\", \"images\")\n",
    "valid_images_dir = os.path.join(\"data\", \"valid\", \"images\")\n",
    "train_dataset = CrackDataset(\n",
    "    list_image_paths(train_images_dir), \n",
    "    os.path.join(\"data\", \"train\", \"labels.pkl\"),\n",
    "    os.path.join(\"data\", \"train\", \"stats.pkl\")\n",
    ")\n",
    "valid_dataset = CrackDataset(\n",
    "    list_image_paths(valid_images_dir),\n",
    "    os.path.join(\"data\", \"valid\", \"labels.pkl\"),\n",
    "    os.path.join(\"data\", \"valid\", \"stats.pkl\")\n",
    ")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4)\n",
    "validation_dataloader = DataLoader\n",
    "early_stopping = EarlyStopping(patience=7, verbose=True, delta=0)\n",
    "num_epochs = 30"
   ],
   "id": "d57468468044cd13",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T09:09:17.980188Z",
     "start_time": "2024-08-03T09:03:02.109540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(num_epochs):\n",
    "    rcnn_model.train()\n",
    "\n",
    "    train_progress_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    for i, data in train_progress_bar:\n",
    "        image_path, image, labels, stats = data\n",
    "        image = image.squeeze(0).numpy()\n",
    "        proposals = generate_proposals(image, transform)\n",
    "        batch_loss = 0.0\n",
    "\n",
    "        for proposal, proposal_box in proposals:\n",
    "            proposal = proposal.unsqueeze(0)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            class_logits, bbox_preds = rcnn_model(proposal)\n",
    "            aggregated_label = get_label_for_proposal(labels, torch.tensor(proposal_box, dtype=torch.long))\n",
    "            loss_class = criterion_class(class_logits, aggregated_label.unsqueeze(0))\n",
    "            best_stat = get_best_bbox_for_proposal(stats, bbox_preds)\n",
    "            loss_bbox = criterion_bbox(bbox_preds, best_stat)\n",
    "            loss = loss_class + loss_bbox\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_loss += loss.item()\n",
    "\n",
    "        train_progress_bar.set_postfix(loss=batch_loss / len(proposals))\n",
    "\n",
    "    rcnn_model.eval()\n",
    "\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validation_dataloader):\n",
    "            image, labels, stats = data\n",
    "            image = image.squeeze(0).numpy()\n",
    "            proposals = generate_proposals(image, transform)\n",
    "\n",
    "            for proposal, proposal_box in proposals:\n",
    "                proposal = proposal.unsqueeze(0)\n",
    "                class_logits, bbox_preds = rcnn_model(proposal)\n",
    "                aggregated_label = get_label_for_proposal(labels, torch.tensor(proposal_box, dtype=torch.long))\n",
    "                best_stat = get_best_bbox_for_proposal(stats, bbox_preds)\n",
    "                loss_class = criterion_class(class_logits, aggregated_label.unsqueeze(0))\n",
    "                loss_bbox = criterion_bbox(bbox_preds, best_stat)\n",
    "                val_loss += (loss_class + loss_bbox).item()\n",
    "\n",
    "    val_loss /= len(validation_dataloader)\n",
    "\n",
    "    print(f'Validation Loss: {val_loss:.6f}')\n",
    "    early_stopping(val_loss, rcnn_model, 'checkpoint.pth')\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered. Stopping training.\")\n",
    "        break"
   ],
   "id": "80195587c758e95f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30:   0%|          | 0/8241 [00:00<?, ?it/s]C:\\Users\\mmale\\.conda\\envs\\crack_detection_torch_1\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:942: UserWarning: Using a target size (torch.Size([0, 4])) that is different to the input size (torch.Size([1, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "Epoch 1/30:   0%|          | 0/8241 [05:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 25\u001B[0m\n\u001B[0;32m     22\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss_class \u001B[38;5;241m+\u001B[39m loss_bbox\n\u001B[0;32m     24\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m---> 25\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     27\u001B[0m     batch_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m     29\u001B[0m train_progress_bar\u001B[38;5;241m.\u001B[39mset_postfix(loss\u001B[38;5;241m=\u001B[39mbatch_loss \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(proposals))\n",
      "File \u001B[1;32m~\\.conda\\envs\\crack_detection_torch_1\\Lib\\site-packages\\torch\\optim\\optimizer.py:484\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    479\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    480\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    481\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    482\u001B[0m             )\n\u001B[1;32m--> 484\u001B[0m out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    485\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    487\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\crack_detection_torch_1\\Lib\\site-packages\\torch\\optim\\optimizer.py:89\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     87\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     88\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[1;32m---> 89\u001B[0m     ret \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     91\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[1;32m~\\.conda\\envs\\crack_detection_torch_1\\Lib\\site-packages\\torch\\optim\\adam.py:226\u001B[0m, in \u001B[0;36mAdam.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    214\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    216\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[0;32m    217\u001B[0m         group,\n\u001B[0;32m    218\u001B[0m         params_with_grad,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    223\u001B[0m         state_steps,\n\u001B[0;32m    224\u001B[0m     )\n\u001B[1;32m--> 226\u001B[0m     adam(\n\u001B[0;32m    227\u001B[0m         params_with_grad,\n\u001B[0;32m    228\u001B[0m         grads,\n\u001B[0;32m    229\u001B[0m         exp_avgs,\n\u001B[0;32m    230\u001B[0m         exp_avg_sqs,\n\u001B[0;32m    231\u001B[0m         max_exp_avg_sqs,\n\u001B[0;32m    232\u001B[0m         state_steps,\n\u001B[0;32m    233\u001B[0m         amsgrad\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamsgrad\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    234\u001B[0m         has_complex\u001B[38;5;241m=\u001B[39mhas_complex,\n\u001B[0;32m    235\u001B[0m         beta1\u001B[38;5;241m=\u001B[39mbeta1,\n\u001B[0;32m    236\u001B[0m         beta2\u001B[38;5;241m=\u001B[39mbeta2,\n\u001B[0;32m    237\u001B[0m         lr\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    238\u001B[0m         weight_decay\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweight_decay\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    239\u001B[0m         eps\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meps\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    240\u001B[0m         maximize\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    241\u001B[0m         foreach\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mforeach\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    242\u001B[0m         capturable\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcapturable\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    243\u001B[0m         differentiable\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    244\u001B[0m         fused\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfused\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    245\u001B[0m         grad_scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrad_scale\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m    246\u001B[0m         found_inf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m    247\u001B[0m     )\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[1;32m~\\.conda\\envs\\crack_detection_torch_1\\Lib\\site-packages\\torch\\optim\\optimizer.py:161\u001B[0m, in \u001B[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    159\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m disabled_func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    160\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 161\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\crack_detection_torch_1\\Lib\\site-packages\\torch\\optim\\adam.py:766\u001B[0m, in \u001B[0;36madam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[0;32m    763\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    764\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[1;32m--> 766\u001B[0m func(\n\u001B[0;32m    767\u001B[0m     params,\n\u001B[0;32m    768\u001B[0m     grads,\n\u001B[0;32m    769\u001B[0m     exp_avgs,\n\u001B[0;32m    770\u001B[0m     exp_avg_sqs,\n\u001B[0;32m    771\u001B[0m     max_exp_avg_sqs,\n\u001B[0;32m    772\u001B[0m     state_steps,\n\u001B[0;32m    773\u001B[0m     amsgrad\u001B[38;5;241m=\u001B[39mamsgrad,\n\u001B[0;32m    774\u001B[0m     has_complex\u001B[38;5;241m=\u001B[39mhas_complex,\n\u001B[0;32m    775\u001B[0m     beta1\u001B[38;5;241m=\u001B[39mbeta1,\n\u001B[0;32m    776\u001B[0m     beta2\u001B[38;5;241m=\u001B[39mbeta2,\n\u001B[0;32m    777\u001B[0m     lr\u001B[38;5;241m=\u001B[39mlr,\n\u001B[0;32m    778\u001B[0m     weight_decay\u001B[38;5;241m=\u001B[39mweight_decay,\n\u001B[0;32m    779\u001B[0m     eps\u001B[38;5;241m=\u001B[39meps,\n\u001B[0;32m    780\u001B[0m     maximize\u001B[38;5;241m=\u001B[39mmaximize,\n\u001B[0;32m    781\u001B[0m     capturable\u001B[38;5;241m=\u001B[39mcapturable,\n\u001B[0;32m    782\u001B[0m     differentiable\u001B[38;5;241m=\u001B[39mdifferentiable,\n\u001B[0;32m    783\u001B[0m     grad_scale\u001B[38;5;241m=\u001B[39mgrad_scale,\n\u001B[0;32m    784\u001B[0m     found_inf\u001B[38;5;241m=\u001B[39mfound_inf,\n\u001B[0;32m    785\u001B[0m )\n",
      "File \u001B[1;32m~\\.conda\\envs\\crack_detection_torch_1\\Lib\\site-packages\\torch\\optim\\adam.py:431\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[0;32m    429\u001B[0m         denom \u001B[38;5;241m=\u001B[39m (max_exp_avg_sqs[i]\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[0;32m    430\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 431\u001B[0m         denom \u001B[38;5;241m=\u001B[39m (exp_avg_sq\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[0;32m    433\u001B[0m     param\u001B[38;5;241m.\u001B[39maddcdiv_(exp_avg, denom, value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39mstep_size)\n\u001B[0;32m    435\u001B[0m \u001B[38;5;66;03m# Lastly, switch back to complex view\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T08:39:31.936260Z",
     "start_time": "2024-08-03T08:39:31.935290Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "34b517dc2db79428",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
