{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T12:53:57.656146Z",
     "start_time": "2024-10-13T12:53:54.408015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from helpers.classifier_with_pretrained_features import Resnext50BasedClassifierForProposals\n",
    "from helpers.datasets import custom_collate_fn, CrackDataset\n",
    "from helpers.early_stopping import EarlyStopping"
   ],
   "id": "f5c1702b2f26f516",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T12:53:57.675861Z",
     "start_time": "2024-10-13T12:53:57.658532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ],
   "id": "a222ee1e673144a3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T12:53:57.685516Z",
     "start_time": "2024-10-13T12:53:57.676866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "proposal_cache = defaultdict(list)\n",
    "\n",
    "\n",
    "def perform_selective_search(image: np.ndarray, image_path: str, batch_size: int = 70) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Perform selective search and return the largest proposals (by area) in three batches after shuffling.\n",
    "    Cache the proposals based on the image path to avoid redundant computation.\n",
    "    \n",
    "    Args:\n",
    "    - image: The input image as a numpy array.\n",
    "    - image_path: The file path to the image (used as the cache key).\n",
    "    - batch_size: The size of each batch (default 50).\n",
    "    \n",
    "    Yields:\n",
    "    - A batch of proposals as a torch.Tensor of shape [batch_size, 4].\n",
    "    \"\"\"\n",
    "    if image_path in proposal_cache:\n",
    "        for start in range(0, len(proposal_cache[image_path]), batch_size):\n",
    "            yield torch.tensor(proposal_cache[image_path][start:start + batch_size], dtype=torch.float32).to(device)\n",
    "    else:\n",
    "        ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "\n",
    "        ss.setBaseImage(image)\n",
    "        ss.switchToSelectiveSearchFast()\n",
    "\n",
    "        rects = ss.process()\n",
    "        boxes = []\n",
    "\n",
    "        for (x, y, w, h) in rects:\n",
    "            area = w * h\n",
    "\n",
    "            boxes.append((x, y, x + w, y + h, area))\n",
    "\n",
    "        boxes = sorted(boxes, key=lambda b: b[4], reverse=True)\n",
    "        boxes = [(x1, y1, x2, y2) for x1, y1, x2, y2, area in boxes]\n",
    "        num_proposals = min(len(boxes), 2 * batch_size)\n",
    "        top_proposals = boxes[:num_proposals]\n",
    "\n",
    "        random.shuffle(top_proposals)\n",
    "\n",
    "        proposal_cache[image_path] = top_proposals\n",
    "\n",
    "        for start in range(0, num_proposals, batch_size):\n",
    "            yield torch.tensor(top_proposals[start:start + batch_size], dtype=torch.float32).to(device)"
   ],
   "id": "1d205e04b56026b8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T12:53:57.691696Z",
     "start_time": "2024-10-13T12:53:57.686521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_loaders() -> tuple[DataLoader, DataLoader]:\n",
    "    train_images_dir = os.path.join(\"data\", \"train_small\", \"images\")\n",
    "    valid_images_dir = os.path.join(\"data\", \"valid_small\", \"images\")\n",
    "    train_coco_path = os.path.join(\"data\", \"train\", \"coco_annotations.json\")\n",
    "    valid_coco_path = os.path.join(\"data\", \"valid\", \"coco_annotations.json\")\n",
    "    train_dataset = CrackDataset(\n",
    "        train_coco_path,\n",
    "        train_images_dir\n",
    "    )\n",
    "    valid_dataset = CrackDataset(\n",
    "        valid_coco_path,\n",
    "        valid_images_dir\n",
    "    )\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "    valid_dataloader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "\n",
    "    return train_dataloader, valid_dataloader"
   ],
   "id": "a3079d112419fc1e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T12:53:57.697781Z",
     "start_time": "2024-10-13T12:53:57.693702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_loop_objects() -> tuple[Resnext50BasedClassifierForProposals, EarlyStopping, torch.nn.BCEWithLogitsLoss, optim.Adam]:\n",
    "    model = Resnext50BasedClassifierForProposals()\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    early_stopping = EarlyStopping(patience=2, verbose=True, delta=0)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    return model, early_stopping, criterion, optimizer"
   ],
   "id": "22919126908270e6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T12:53:57.709171Z",
     "start_time": "2024-10-13T12:53:57.698787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 25\n",
    "\n",
    "\n",
    "def validate(\n",
    "        model: Resnext50BasedClassifierForProposals,\n",
    "        valid_loader: DataLoader,\n",
    "        criterion: torch.nn.BCEWithLogitsLoss,\n",
    "        history: dict[str, list[float]]\n",
    ") -> tuple[float, float]:\n",
    "    model.eval()\n",
    "\n",
    "    valid_loss = 0.0\n",
    "    correct_valid = 0\n",
    "    total_valid = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device).float()\n",
    "            outputs = model(images).squeeze(1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item()\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            correct_valid += predicted.eq(labels).sum().item()\n",
    "            total_valid += labels.size(0)\n",
    "\n",
    "    valid_loss /= len(valid_loader.dataset)\n",
    "    history[\"valid_loss\"].append(valid_loss)\n",
    "\n",
    "    return 100. * correct_valid / total_valid, valid_loss\n",
    "\n",
    "\n",
    "def run_training_loop() -> tuple[dict, float]:\n",
    "    checkpoint_path = os.path.join(\"checkpoints\", f\"resnext50_32x4d_classifier_with_proposals.pt\")\n",
    "    train_loader, valid_loader = get_loaders()\n",
    "    model, early_stopping, criterion, optimizer = get_loop_objects()\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"valid_loss\": []\n",
    "    }\n",
    "    valid_accuracy = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "            for images, labels in tepoch:\n",
    "                images = torch.Tensor(images).to(device)\n",
    "                #images, labels = torch.Tensor(images).to(device), torch.Tensor(labels).to(device).float()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs: torch.Tensor = model(images)\n",
    "                # Assuming we have a single label per batch, for example, maximum label\n",
    "                # Modify based on the specific logic for proposal classification\n",
    "                loss = criterion(outputs.max(dim=1)[0], labels)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                correct_train += (predicted == labels.unsqueeze(1)).sum().item()\n",
    "                total_train += labels.numel()\n",
    "\n",
    "                tepoch.set_postfix(loss=train_loss / total_train, accuracy=100. * correct_train / total_train)\n",
    "\n",
    "        valid_accuracy, valid_loss = validate(model, valid_loader, criterion, history)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "\n",
    "        print(f\"Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_accuracy:.2f}%\")\n",
    "        early_stopping(valid_loss, model, checkpoint_path)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    return history, valid_accuracy"
   ],
   "id": "5a0b7e922d4fc39b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T12:54:17.040323Z",
     "start_time": "2024-10-13T12:53:57.710176Z"
    }
   },
   "cell_type": "code",
   "source": "history, valid_accuracy = run_training_loop()",
   "id": "a699019f641b3a0a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25:   0%|          | 0/3 [00:14<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m history, valid_accuracy \u001B[38;5;241m=\u001B[39m run_training_loop()\n",
      "Cell \u001B[1;32mIn[6], line 51\u001B[0m, in \u001B[0;36mrun_training_loop\u001B[1;34m()\u001B[0m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tqdm(train_loader, unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m tepoch:\n\u001B[0;32m     49\u001B[0m     tepoch\u001B[38;5;241m.\u001B[39mset_description(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 51\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m images, labels \u001B[38;5;129;01min\u001B[39;00m tepoch:\n\u001B[0;32m     52\u001B[0m         images \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor(images)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     53\u001B[0m         \u001B[38;5;66;03m#images, labels = torch.Tensor(images).to(device), torch.Tensor(labels).to(device).float()\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (crack_detection_torch_1)",
   "language": "python",
   "name": "crack_detection_torch_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
